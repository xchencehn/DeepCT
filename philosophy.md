

### 设计理念（Design Philosophy）
#### 1. 无侵入、可插拔

DeepCT 的核心目标不是修改模型，而是**观察模型**。  
因此我们设计了一个**透明包装层 (Wrapper Layer)**，  
在不改变任何 transformers 源代码与类结构的前提下，  
即可**动态挂载 hooks**，采集任意层的隐藏状态与注意力特征，用于指标分析。

设计哲学：  
把大型语言模型看成“黑盒物理系统”。  
DeepCT 不打开这个盒子内部的实现，而是用传感器（hooks）去观测它的行为模式。

#### 2. 内在分析优先

传统评估只关注下游指标（loss、accuracy），  
DeepCT 关注的是模型的**内在几何状态演化**，  
即：层与层之间、token 表征之间、注意力结构之间的统计与几何特性。

这种视角让我们能研究：

- 模型**在哪一层压缩了语义空间**；
- 哪些层的**能量流动失衡**；
- 注意力分布**是否退化或塌缩**；
- 层间相关性**是否表明收敛或重构**。

DeepCT 认为：大型 Transformer 是在高维流形上进行动力学演化，  
而**几何流动 + 信息熵**是描述这一演化的关键物理量。

#### 3. 科研模块化

每个指标（metric）都是独立插件，符合：

- **统一 API**：`update(layer_name, hidden_states)`
- **轻量通道**：只需激活数据，不改模型逻辑
- **无状态依赖**：每个指标模块彼此独立

研究者可任意增删指标，如：

- 信息论：熵、互信息、注意力分布
- 几何论：内在维度、流形曲率、Wasserstein 距离
- 能量论：层间能量守恒、激活流动

#### 4. 科研即复制

DeepCT 的所有实验指标都会：

- 自动时间戳；
- 按层存储；
- 可导出 JSON、DataFrame；
- 可加载复现。

这确保你的几何实验完全可重现，  
可以直接作为论文附录或比较图表的数据源。